## Lab1
### SVM
CIFAR-10
Linear SVM
best validation accuracy achieved during cross-validation: 0.393000  
  <img src="https://i.imgur.com/k833ky2.png" width="30%">
  <img src="https://i.imgur.com/8M5uvm5.png" width="30%">
### FC
*    **Backpropogation**

  <img src="https://i.imgur.com/uBI2Cx8.png" width="40%">
  <img src="https://i.imgur.com/lIDoLxi.png" width="30%">
  <img src="https://i.imgur.com/2uNg81v.png" width="90%">


## Lab2
### 1. CNN
![](https://i.imgur.com/UTTRWPu.png)
(Epoch 1 / 1) train acc: 0.504000; val_acc: 0.499000

*    Conv layer backpropagation
![](https://i.imgur.com/cbsjYKu.png)
![](https://i.imgur.com/2qaVlkl.png)
![](https://i.imgur.com/jz2vvjB.png)

*    Max-Pooling Backpropagation
![](https://i.imgur.com/9msUema.png)



### 2. FC with different Update rules
  <img src="https://i.imgur.com/eVzGN6G.png" width="90%">

#### SGD_momentum
![](https://i.imgur.com/BIRhkwU.png)
#### RMS prop
![](https://i.imgur.com/1EIuD1v.png)
#### Adam
![](https://i.imgur.com/IexqG3t.png)
### 3. BatchNorm
![](https://i.imgur.com/RKczP7F.png)
##### backpropogation
![](https://i.imgur.com/n7rAEZL.png)
### 4. Dropout
![](https://i.imgur.com/fKeBokF.png)
